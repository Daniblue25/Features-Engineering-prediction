{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La prédiction avec les réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_dataset.csv')\n",
    "df_test = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>duration_tot_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3897.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7662.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Airline  Source  Destination  Total_Stops  Additional_Info   Price  Date  \\\n",
       "0        3       0            5          0.0                8  3897.0    24   \n",
       "1        1       3            0          2.0                8  7662.0     1   \n",
       "\n",
       "   Month  Arrival_hour  Arrival_min  Dep_hour  Dep_min  duration_tot_min  \n",
       "0      3             1           10        22       20               170  \n",
       "1      5            13           15         5       50               445  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 1, 4, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Destination'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encodons la variable Airline\n",
    "\n",
    "On constate qu'il a jusqu'a 11 valeurs uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_df_train = pd.get_dummies(df_train, columns = ['Airline','Destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>...</th>\n",
       "      <th>Airline_8</th>\n",
       "      <th>Airline_9</th>\n",
       "      <th>Airline_10</th>\n",
       "      <th>Airline_11</th>\n",
       "      <th>Destination_0</th>\n",
       "      <th>Destination_1</th>\n",
       "      <th>Destination_2</th>\n",
       "      <th>Destination_3</th>\n",
       "      <th>Destination_4</th>\n",
       "      <th>Destination_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3897.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7662.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Total_Stops  Additional_Info   Price  Date  Month  Arrival_hour  \\\n",
       "0       0          0.0                8  3897.0    24      3             1   \n",
       "1       3          2.0                8  7662.0     1      5            13   \n",
       "\n",
       "   Arrival_min  Dep_hour  Dep_min  ...  Airline_8  Airline_9  Airline_10  \\\n",
       "0           10        22       20  ...          0          0           0   \n",
       "1           15         5       50  ...          0          0           0   \n",
       "\n",
       "   Airline_11  Destination_0  Destination_1  Destination_2  Destination_3  \\\n",
       "0           0              0              0              0              0   \n",
       "1           0              1              0              0              0   \n",
       "\n",
       "   Destination_4  Destination_5  \n",
       "0              0              1  \n",
       "1              0              0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des données\n",
    "X = hot_df_train.drop(['Price'], axis=1)\n",
    "y = hot_df_train['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensemble d'entraînement et ensemble de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des train et test\n",
    "X_train_norm = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_norm = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_norm = sc.fit_transform(X_train)\n",
    "X_test_norm = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train_norm.drop('Airline_11', axis=1)\n",
    "X_test_norm = X_test_norm.drop('Airline_11', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8544, 28), (2137, 28))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Création du modèle de réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 128)               3712      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,081\n",
      "Trainable params: 14,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#lenght = len(X_train_norm.columns)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, kernel_initializer= 'uniform', activation='relu', input_dim = 28))\n",
    "model.add(Dense(64,kernel_initializer= 'uniform', activation='relu'))\n",
    "model.add(Dense(32, kernel_initializer= 'uniform', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,kernel_initializer= 'uniform'))\n",
    "\n",
    "model.compile(optimizer= 'adam', loss='mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 14953994.0000 - val_loss: 9636132.0000\n",
      "Epoch 2/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 12285653.0000 - val_loss: 8685806.0000\n",
      "Epoch 3/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 11775930.0000 - val_loss: 8081566.0000\n",
      "Epoch 4/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 11127526.0000 - val_loss: 7590539.0000\n",
      "Epoch 5/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 11019430.0000 - val_loss: 7131073.0000\n",
      "Epoch 6/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 10320180.0000 - val_loss: 7008429.0000\n",
      "Epoch 7/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 10233891.0000 - val_loss: 7116664.0000\n",
      "Epoch 8/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 10003043.0000 - val_loss: 6510281.0000\n",
      "Epoch 9/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9914844.0000 - val_loss: 6355158.0000\n",
      "Epoch 10/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 10186910.0000 - val_loss: 6573720.0000\n",
      "Epoch 11/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 9698644.0000 - val_loss: 6368066.0000\n",
      "Epoch 12/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9478008.0000 - val_loss: 5833553.0000\n",
      "Epoch 13/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9691575.0000 - val_loss: 5795925.5000\n",
      "Epoch 14/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 9592073.0000 - val_loss: 5911010.5000\n",
      "Epoch 15/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9397491.0000 - val_loss: 5742754.0000\n",
      "Epoch 16/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9538298.0000 - val_loss: 5768465.0000\n",
      "Epoch 17/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9245471.0000 - val_loss: 5787136.5000\n",
      "Epoch 18/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9431189.0000 - val_loss: 5501874.5000\n",
      "Epoch 19/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9478049.0000 - val_loss: 5862080.5000\n",
      "Epoch 20/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9295668.0000 - val_loss: 5459314.5000\n",
      "Epoch 21/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8808685.0000 - val_loss: 5716831.0000\n",
      "Epoch 22/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9134807.0000 - val_loss: 5576687.0000\n",
      "Epoch 23/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 9047028.0000 - val_loss: 5822676.0000\n",
      "Epoch 24/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 8880470.0000 - val_loss: 5453433.0000\n",
      "Epoch 25/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9404440.0000 - val_loss: 5469948.0000\n",
      "Epoch 26/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9103289.0000 - val_loss: 5583121.5000\n",
      "Epoch 27/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9074741.0000 - val_loss: 5417908.0000\n",
      "Epoch 28/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9249152.0000 - val_loss: 5172912.5000\n",
      "Epoch 29/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9280133.0000 - val_loss: 5540074.5000\n",
      "Epoch 30/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9195963.0000 - val_loss: 5765020.0000\n",
      "Epoch 31/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8906512.0000 - val_loss: 5293961.0000\n",
      "Epoch 32/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9139458.0000 - val_loss: 5414840.5000\n",
      "Epoch 33/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9263564.0000 - val_loss: 5296760.0000\n",
      "Epoch 34/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8696622.0000 - val_loss: 5448663.5000\n",
      "Epoch 35/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 8881024.0000 - val_loss: 5548570.0000\n",
      "Epoch 36/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 9069432.0000 - val_loss: 5188588.5000\n",
      "Epoch 37/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8831220.0000 - val_loss: 5220197.5000\n",
      "Epoch 38/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8815615.0000 - val_loss: 5305658.5000\n",
      "Epoch 39/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8724528.0000 - val_loss: 5073833.0000\n",
      "Epoch 40/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8726288.0000 - val_loss: 4987682.5000\n",
      "Epoch 41/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9115842.0000 - val_loss: 5284428.0000\n",
      "Epoch 42/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 8938347.0000 - val_loss: 5298556.0000\n",
      "Epoch 43/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9087922.0000 - val_loss: 5055090.0000\n",
      "Epoch 44/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8990208.0000 - val_loss: 5217136.0000\n",
      "Epoch 45/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9001335.0000 - val_loss: 5030573.5000\n",
      "Epoch 46/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8838925.0000 - val_loss: 5175600.5000\n",
      "Epoch 47/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9026436.0000 - val_loss: 5111964.5000\n",
      "Epoch 48/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 9057237.0000 - val_loss: 5068335.5000\n",
      "Epoch 49/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 8662173.0000 - val_loss: 5115265.0000\n",
      "Epoch 50/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 8939268.0000 - val_loss: 5300565.0000\n",
      "Epoch 51/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8811942.0000 - val_loss: 5411213.5000\n",
      "Epoch 52/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8912134.0000 - val_loss: 5202542.5000\n",
      "Epoch 53/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8643496.0000 - val_loss: 4983916.0000\n",
      "Epoch 54/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 9068542.0000 - val_loss: 4986834.0000\n",
      "Epoch 55/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 8551505.0000 - val_loss: 4913149.0000\n",
      "Epoch 56/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8538612.0000 - val_loss: 5038285.0000\n",
      "Epoch 57/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8737408.0000 - val_loss: 5048401.0000\n",
      "Epoch 58/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8590671.0000 - val_loss: 4848966.0000\n",
      "Epoch 59/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8762340.0000 - val_loss: 5212748.5000\n",
      "Epoch 60/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8347338.5000 - val_loss: 5145431.0000\n",
      "Epoch 61/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8675246.0000 - val_loss: 4941522.0000\n",
      "Epoch 62/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8387095.0000 - val_loss: 4971654.0000\n",
      "Epoch 63/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8783644.0000 - val_loss: 5224502.5000\n",
      "Epoch 64/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8766585.0000 - val_loss: 4933315.0000\n",
      "Epoch 65/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8267854.5000 - val_loss: 4956154.0000\n",
      "Epoch 66/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8881193.0000 - val_loss: 4955022.5000\n",
      "Epoch 67/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 8563838.0000 - val_loss: 4849797.0000\n",
      "Epoch 68/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8665395.0000 - val_loss: 5195965.5000\n",
      "Epoch 69/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8447820.0000 - val_loss: 5007025.5000\n",
      "Epoch 70/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8513058.0000 - val_loss: 4798769.0000\n",
      "Epoch 71/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8604038.0000 - val_loss: 5155480.0000\n",
      "Epoch 72/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8543788.0000 - val_loss: 4780857.0000\n",
      "Epoch 73/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8481804.0000 - val_loss: 4881868.5000\n",
      "Epoch 74/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8540519.0000 - val_loss: 4760123.0000\n",
      "Epoch 75/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 8495039.0000 - val_loss: 4743396.0000\n",
      "Epoch 76/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 8476095.0000 - val_loss: 4672135.0000\n",
      "Epoch 77/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8373484.0000 - val_loss: 4747301.0000\n",
      "Epoch 78/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8277227.0000 - val_loss: 4748193.0000\n",
      "Epoch 79/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 8802152.0000 - val_loss: 4652802.0000\n",
      "Epoch 80/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8321464.0000 - val_loss: 4929796.0000\n",
      "Epoch 81/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8601076.0000 - val_loss: 5158267.5000\n",
      "Epoch 82/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8659876.0000 - val_loss: 4846211.0000\n",
      "Epoch 83/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8552650.0000 - val_loss: 5081397.0000\n",
      "Epoch 84/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 8408107.0000 - val_loss: 4995892.0000\n",
      "Epoch 85/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 8207305.5000 - val_loss: 4934213.0000\n",
      "Epoch 86/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8408789.0000 - val_loss: 4874544.0000\n",
      "Epoch 87/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8456048.0000 - val_loss: 4658318.0000\n",
      "Epoch 88/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8196431.5000 - val_loss: 4724894.5000\n",
      "Epoch 89/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8637875.0000 - val_loss: 4608009.0000\n",
      "Epoch 90/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8461047.0000 - val_loss: 4685903.5000\n",
      "Epoch 91/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8636568.0000 - val_loss: 4659800.0000\n",
      "Epoch 92/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8048749.5000 - val_loss: 4500795.0000\n",
      "Epoch 93/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8195366.5000 - val_loss: 4428118.5000\n",
      "Epoch 94/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 8621682.0000 - val_loss: 4468922.5000\n",
      "Epoch 95/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8478624.0000 - val_loss: 4661292.5000\n",
      "Epoch 96/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8157681.5000 - val_loss: 4742434.5000\n",
      "Epoch 97/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8223962.5000 - val_loss: 4490513.0000\n",
      "Epoch 98/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8078514.5000 - val_loss: 4705096.0000\n",
      "Epoch 99/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8345716.0000 - val_loss: 4336404.5000\n",
      "Epoch 100/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8455483.0000 - val_loss: 4533732.5000\n",
      "Epoch 101/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8576865.0000 - val_loss: 4498056.0000\n",
      "Epoch 102/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8214327.5000 - val_loss: 4737153.0000\n",
      "Epoch 103/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8570772.0000 - val_loss: 4610556.0000\n",
      "Epoch 104/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8318116.0000 - val_loss: 4495165.0000\n",
      "Epoch 105/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 8312077.5000 - val_loss: 4376551.5000\n",
      "Epoch 106/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 8337776.0000 - val_loss: 4370157.0000\n",
      "Epoch 107/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8271300.5000 - val_loss: 4571082.5000\n",
      "Epoch 108/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8008488.5000 - val_loss: 4457645.0000\n",
      "Epoch 109/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8344261.5000 - val_loss: 4444194.5000\n",
      "Epoch 110/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8317406.5000 - val_loss: 4424559.5000\n",
      "Epoch 111/500\n",
      "267/267 [==============================] - 3s 13ms/step - loss: 7975272.5000 - val_loss: 4645772.0000\n",
      "Epoch 112/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7947012.0000 - val_loss: 4338624.0000\n",
      "Epoch 113/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8164090.0000 - val_loss: 4902504.5000\n",
      "Epoch 114/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8354946.5000 - val_loss: 4225306.5000\n",
      "Epoch 115/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8262901.5000 - val_loss: 4816924.0000\n",
      "Epoch 116/500\n",
      "267/267 [==============================] - 4s 14ms/step - loss: 8356721.0000 - val_loss: 4313460.5000\n",
      "Epoch 117/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8477443.0000 - val_loss: 4281484.5000\n",
      "Epoch 118/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 8255024.0000 - val_loss: 4333121.5000\n",
      "Epoch 119/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8115736.0000 - val_loss: 4356995.5000\n",
      "Epoch 120/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 8060501.5000 - val_loss: 4537120.0000\n",
      "Epoch 121/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7977224.0000 - val_loss: 4253517.5000\n",
      "Epoch 122/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8074643.5000 - val_loss: 4396968.5000\n",
      "Epoch 123/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7886410.5000 - val_loss: 4234596.5000\n",
      "Epoch 124/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 7902670.5000 - val_loss: 4387951.5000\n",
      "Epoch 125/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 7975730.0000 - val_loss: 4417542.0000\n",
      "Epoch 126/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8121707.5000 - val_loss: 4365931.0000\n",
      "Epoch 127/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7973696.0000 - val_loss: 4321700.5000\n",
      "Epoch 128/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7989623.5000 - val_loss: 4464725.5000\n",
      "Epoch 129/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7924354.5000 - val_loss: 4166194.0000\n",
      "Epoch 130/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8121740.0000 - val_loss: 4203290.0000\n",
      "Epoch 131/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7876522.5000 - val_loss: 4592566.5000\n",
      "Epoch 132/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7691612.5000 - val_loss: 4352931.5000\n",
      "Epoch 133/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7940759.5000 - val_loss: 4152359.2500\n",
      "Epoch 134/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7858602.5000 - val_loss: 4358630.0000\n",
      "Epoch 135/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8274484.5000 - val_loss: 4293448.5000\n",
      "Epoch 136/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7679889.5000 - val_loss: 4235247.0000\n",
      "Epoch 137/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7793387.5000 - val_loss: 4294224.5000\n",
      "Epoch 138/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8138955.5000 - val_loss: 4248248.0000\n",
      "Epoch 139/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8210640.0000 - val_loss: 4069084.2500\n",
      "Epoch 140/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7858952.0000 - val_loss: 4087491.2500\n",
      "Epoch 141/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7941751.5000 - val_loss: 4124801.5000\n",
      "Epoch 142/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 7747523.5000 - val_loss: 4163600.7500\n",
      "Epoch 143/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 8064560.0000 - val_loss: 4277124.0000\n",
      "Epoch 144/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 8136754.0000 - val_loss: 4091048.2500\n",
      "Epoch 145/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8015494.5000 - val_loss: 4148737.7500\n",
      "Epoch 146/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7866502.5000 - val_loss: 4111503.7500\n",
      "Epoch 147/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7988740.5000 - val_loss: 4116864.2500\n",
      "Epoch 148/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7622943.5000 - val_loss: 4124269.0000\n",
      "Epoch 149/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7606643.5000 - val_loss: 4231616.0000\n",
      "Epoch 150/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7893776.5000 - val_loss: 4241946.5000\n",
      "Epoch 151/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7915094.0000 - val_loss: 4056125.2500\n",
      "Epoch 152/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7782115.0000 - val_loss: 3828831.2500\n",
      "Epoch 153/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7791853.5000 - val_loss: 4106448.5000\n",
      "Epoch 154/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7828911.0000 - val_loss: 3950489.7500\n",
      "Epoch 155/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7913847.5000 - val_loss: 4069636.7500\n",
      "Epoch 156/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 8105022.5000 - val_loss: 3850389.0000\n",
      "Epoch 157/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7627256.5000 - val_loss: 4045466.5000\n",
      "Epoch 158/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7885981.0000 - val_loss: 4027229.0000\n",
      "Epoch 159/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7554587.0000 - val_loss: 3756475.7500\n",
      "Epoch 160/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7835248.5000 - val_loss: 3819845.7500\n",
      "Epoch 161/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7764620.0000 - val_loss: 3854103.0000\n",
      "Epoch 162/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7585220.0000 - val_loss: 3955708.7500\n",
      "Epoch 163/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7552260.5000 - val_loss: 4256310.5000\n",
      "Epoch 164/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7776319.0000 - val_loss: 4061673.2500\n",
      "Epoch 165/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7774015.5000 - val_loss: 4088746.7500\n",
      "Epoch 166/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7449469.0000 - val_loss: 4058711.0000\n",
      "Epoch 167/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7657303.5000 - val_loss: 3908554.7500\n",
      "Epoch 168/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7693245.0000 - val_loss: 3865113.5000\n",
      "Epoch 169/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7609720.5000 - val_loss: 3835970.2500\n",
      "Epoch 170/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7640304.0000 - val_loss: 3785387.0000\n",
      "Epoch 171/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7835578.0000 - val_loss: 3968897.0000\n",
      "Epoch 172/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 7592918.0000 - val_loss: 3802526.7500\n",
      "Epoch 173/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7490228.0000 - val_loss: 3804972.7500\n",
      "Epoch 174/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7827659.0000 - val_loss: 3985052.0000\n",
      "Epoch 175/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 7686192.0000 - val_loss: 3968624.5000\n",
      "Epoch 176/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7722324.5000 - val_loss: 4059671.7500\n",
      "Epoch 177/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7948535.0000 - val_loss: 3818030.5000\n",
      "Epoch 178/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7598143.0000 - val_loss: 3996902.2500\n",
      "Epoch 179/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 7491740.5000 - val_loss: 3766573.5000\n",
      "Epoch 180/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 7508963.5000 - val_loss: 4091501.5000\n",
      "Epoch 181/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7777909.0000 - val_loss: 3746527.7500\n",
      "Epoch 182/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7653902.0000 - val_loss: 3969482.2500\n",
      "Epoch 183/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7426530.0000 - val_loss: 3730360.5000\n",
      "Epoch 184/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7621737.0000 - val_loss: 3851805.5000\n",
      "Epoch 185/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7459746.0000 - val_loss: 3613056.2500\n",
      "Epoch 186/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7394127.0000 - val_loss: 3794493.2500\n",
      "Epoch 187/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7613965.0000 - val_loss: 3740654.0000\n",
      "Epoch 188/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7626343.5000 - val_loss: 3657798.7500\n",
      "Epoch 189/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7571065.0000 - val_loss: 3617835.0000\n",
      "Epoch 190/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7712915.5000 - val_loss: 3626451.7500\n",
      "Epoch 191/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7561881.0000 - val_loss: 3519520.2500\n",
      "Epoch 192/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7290170.0000 - val_loss: 3705958.2500\n",
      "Epoch 193/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7497367.0000 - val_loss: 3568422.0000\n",
      "Epoch 194/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7537008.5000 - val_loss: 3515756.2500\n",
      "Epoch 195/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7513727.5000 - val_loss: 3715031.2500\n",
      "Epoch 196/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7582430.5000 - val_loss: 4050458.5000\n",
      "Epoch 197/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7482961.5000 - val_loss: 3689801.5000\n",
      "Epoch 198/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7867442.5000 - val_loss: 3752181.5000\n",
      "Epoch 199/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7362130.0000 - val_loss: 3890327.7500\n",
      "Epoch 200/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7185282.0000 - val_loss: 3624688.0000\n",
      "Epoch 201/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7516635.5000 - val_loss: 3533263.2500\n",
      "Epoch 202/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 7459711.0000 - val_loss: 3593969.5000\n",
      "Epoch 203/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7242013.0000 - val_loss: 3465408.5000\n",
      "Epoch 204/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7265185.0000 - val_loss: 3787495.5000\n",
      "Epoch 205/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7283857.0000 - val_loss: 3683203.5000\n",
      "Epoch 206/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7482637.0000 - val_loss: 3555586.5000\n",
      "Epoch 207/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7366344.0000 - val_loss: 3596965.7500\n",
      "Epoch 208/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7617358.0000 - val_loss: 3435861.7500\n",
      "Epoch 209/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7356795.5000 - val_loss: 3458266.0000\n",
      "Epoch 210/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7181402.0000 - val_loss: 3998573.2500\n",
      "Epoch 211/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 7181059.5000 - val_loss: 3448712.2500\n",
      "Epoch 212/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 7346607.5000 - val_loss: 3847358.5000\n",
      "Epoch 213/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7631578.5000 - val_loss: 3844234.0000\n",
      "Epoch 214/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7845133.5000 - val_loss: 3463997.0000\n",
      "Epoch 215/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7182033.5000 - val_loss: 3652888.2500\n",
      "Epoch 216/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7274711.5000 - val_loss: 3521571.7500\n",
      "Epoch 217/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 7514500.5000 - val_loss: 3500326.0000\n",
      "Epoch 218/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7097198.5000 - val_loss: 3563403.5000\n",
      "Epoch 219/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7198586.0000 - val_loss: 3528601.5000\n",
      "Epoch 220/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7306053.5000 - val_loss: 3733380.7500\n",
      "Epoch 221/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7558274.5000 - val_loss: 3546735.0000\n",
      "Epoch 222/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7176409.5000 - val_loss: 3485012.5000\n",
      "Epoch 223/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7316043.0000 - val_loss: 3570519.5000\n",
      "Epoch 224/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7302798.0000 - val_loss: 3473775.0000\n",
      "Epoch 225/500\n",
      "267/267 [==============================] - 1s 6ms/step - loss: 7226099.0000 - val_loss: 3775425.0000\n",
      "Epoch 226/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 7413778.0000 - val_loss: 3572726.2500\n",
      "Epoch 227/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7163909.0000 - val_loss: 3499731.0000\n",
      "Epoch 228/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7529661.0000 - val_loss: 3442884.7500\n",
      "Epoch 229/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7378790.5000 - val_loss: 3632728.2500\n",
      "Epoch 230/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7726685.5000 - val_loss: 3381769.0000\n",
      "Epoch 231/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7317086.0000 - val_loss: 3673511.2500\n",
      "Epoch 232/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 7346991.5000 - val_loss: 3483266.5000\n",
      "Epoch 233/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7382609.0000 - val_loss: 3345781.7500\n",
      "Epoch 234/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7036517.5000 - val_loss: 3839784.2500\n",
      "Epoch 235/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7161228.5000 - val_loss: 3612710.0000\n",
      "Epoch 236/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7380494.0000 - val_loss: 3392551.5000\n",
      "Epoch 237/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7468878.5000 - val_loss: 3772886.2500\n",
      "Epoch 238/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7250309.0000 - val_loss: 3352995.2500\n",
      "Epoch 239/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7134321.5000 - val_loss: 3602665.7500\n",
      "Epoch 240/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7208498.5000 - val_loss: 3387533.7500\n",
      "Epoch 241/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7226865.5000 - val_loss: 3451386.2500\n",
      "Epoch 242/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7303667.5000 - val_loss: 3402336.7500\n",
      "Epoch 243/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7285239.5000 - val_loss: 3350860.0000\n",
      "Epoch 244/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7444686.5000 - val_loss: 3675804.0000\n",
      "Epoch 245/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 7308931.0000 - val_loss: 3213998.7500\n",
      "Epoch 246/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7203507.0000 - val_loss: 3314674.5000\n",
      "Epoch 247/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7225932.5000 - val_loss: 3393147.2500\n",
      "Epoch 248/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7269091.5000 - val_loss: 3309330.0000\n",
      "Epoch 249/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7291452.0000 - val_loss: 3317512.5000\n",
      "Epoch 250/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 7020003.0000 - val_loss: 3416151.7500\n",
      "Epoch 251/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 7067058.0000 - val_loss: 3249961.5000\n",
      "Epoch 252/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7293605.5000 - val_loss: 3496008.5000\n",
      "Epoch 253/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7367528.5000 - val_loss: 3495346.2500\n",
      "Epoch 254/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7496633.5000 - val_loss: 3436351.2500\n",
      "Epoch 255/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7143700.0000 - val_loss: 3312234.0000\n",
      "Epoch 256/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6924257.0000 - val_loss: 3460027.7500\n",
      "Epoch 257/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7343822.0000 - val_loss: 3233360.7500\n",
      "Epoch 258/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7447305.5000 - val_loss: 3249136.2500\n",
      "Epoch 259/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7249206.0000 - val_loss: 3575766.2500\n",
      "Epoch 260/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7067993.0000 - val_loss: 3407307.7500\n",
      "Epoch 261/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7453040.5000 - val_loss: 3461385.0000\n",
      "Epoch 262/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7114705.5000 - val_loss: 3289795.2500\n",
      "Epoch 263/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7241876.0000 - val_loss: 3972095.5000\n",
      "Epoch 264/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7033104.0000 - val_loss: 3464939.5000\n",
      "Epoch 265/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7092576.0000 - val_loss: 3248890.7500\n",
      "Epoch 266/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7186929.5000 - val_loss: 3252764.5000\n",
      "Epoch 267/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6928593.0000 - val_loss: 3184369.7500\n",
      "Epoch 268/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7285250.0000 - val_loss: 3345461.7500\n",
      "Epoch 269/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7052773.5000 - val_loss: 3334050.5000\n",
      "Epoch 270/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6988088.5000 - val_loss: 3648247.5000\n",
      "Epoch 271/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7270050.5000 - val_loss: 3516066.2500\n",
      "Epoch 272/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7113197.5000 - val_loss: 3316361.5000\n",
      "Epoch 273/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 7164818.0000 - val_loss: 3585062.2500\n",
      "Epoch 274/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6768279.0000 - val_loss: 3359830.2500\n",
      "Epoch 275/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7145997.0000 - val_loss: 3332494.0000\n",
      "Epoch 276/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7017116.0000 - val_loss: 3276223.7500\n",
      "Epoch 277/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7267806.0000 - val_loss: 3290204.2500\n",
      "Epoch 278/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7089692.0000 - val_loss: 3769459.7500\n",
      "Epoch 279/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7051329.5000 - val_loss: 3239035.5000\n",
      "Epoch 280/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6994061.0000 - val_loss: 3819501.0000\n",
      "Epoch 281/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7030730.5000 - val_loss: 3397722.5000\n",
      "Epoch 282/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 7122675.0000 - val_loss: 3621818.7500\n",
      "Epoch 283/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 6754908.5000 - val_loss: 3217135.5000\n",
      "Epoch 284/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6747841.0000 - val_loss: 3433394.0000\n",
      "Epoch 285/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6861151.5000 - val_loss: 3422755.2500\n",
      "Epoch 286/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6969879.5000 - val_loss: 3622269.0000\n",
      "Epoch 287/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6974435.5000 - val_loss: 3395257.7500\n",
      "Epoch 288/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7360059.0000 - val_loss: 3703171.0000\n",
      "Epoch 289/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7089366.0000 - val_loss: 3295655.2500\n",
      "Epoch 290/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 7282376.5000 - val_loss: 3529805.2500\n",
      "Epoch 291/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7047678.5000 - val_loss: 3483476.2500\n",
      "Epoch 292/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6816203.5000 - val_loss: 3520301.7500\n",
      "Epoch 293/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6986582.5000 - val_loss: 3390518.2500\n",
      "Epoch 294/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6853650.0000 - val_loss: 3381811.7500\n",
      "Epoch 295/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7184275.0000 - val_loss: 3402575.2500\n",
      "Epoch 296/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 6772663.5000 - val_loss: 3280933.7500\n",
      "Epoch 297/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6978761.5000 - val_loss: 3507971.5000\n",
      "Epoch 298/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 6717741.0000 - val_loss: 3651835.5000\n",
      "Epoch 299/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7002960.5000 - val_loss: 3366090.7500\n",
      "Epoch 300/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6913154.5000 - val_loss: 3499439.2500\n",
      "Epoch 301/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6800745.5000 - val_loss: 3432479.5000\n",
      "Epoch 302/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6866796.0000 - val_loss: 3414345.5000\n",
      "Epoch 303/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6793821.0000 - val_loss: 3461167.7500\n",
      "Epoch 304/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7486351.0000 - val_loss: 3115459.5000\n",
      "Epoch 305/500\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 6715903.0000 - val_loss: 3451710.0000\n",
      "Epoch 306/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6916030.0000 - val_loss: 3265870.0000\n",
      "Epoch 307/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6816223.0000 - val_loss: 3415771.0000\n",
      "Epoch 308/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7077835.5000 - val_loss: 3601862.7500\n",
      "Epoch 309/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6778296.0000 - val_loss: 3414159.5000\n",
      "Epoch 310/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6836225.0000 - val_loss: 3565362.0000\n",
      "Epoch 311/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6799362.0000 - val_loss: 3187801.0000\n",
      "Epoch 312/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6989582.0000 - val_loss: 3140734.5000\n",
      "Epoch 313/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6932218.5000 - val_loss: 3568223.5000\n",
      "Epoch 314/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 7021057.0000 - val_loss: 3449001.7500\n",
      "Epoch 315/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7019372.5000 - val_loss: 3352298.7500\n",
      "Epoch 316/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7051558.0000 - val_loss: 3178384.7500\n",
      "Epoch 317/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7183885.5000 - val_loss: 3324015.2500\n",
      "Epoch 318/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 6999190.0000 - val_loss: 3224817.0000\n",
      "Epoch 319/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7079503.0000 - val_loss: 3233839.5000\n",
      "Epoch 320/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7186257.0000 - val_loss: 3462664.2500\n",
      "Epoch 321/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7051717.0000 - val_loss: 3331488.2500\n",
      "Epoch 322/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7022498.5000 - val_loss: 3269046.2500\n",
      "Epoch 323/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 6893578.0000 - val_loss: 3091566.5000\n",
      "Epoch 324/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6852050.5000 - val_loss: 3480324.2500\n",
      "Epoch 325/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7000125.0000 - val_loss: 3406288.0000\n",
      "Epoch 326/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6887881.5000 - val_loss: 3656026.2500\n",
      "Epoch 327/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6623369.0000 - val_loss: 3737390.5000\n",
      "Epoch 328/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6818986.0000 - val_loss: 3600938.2500\n",
      "Epoch 329/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6970151.0000 - val_loss: 3179162.7500\n",
      "Epoch 330/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7073452.0000 - val_loss: 3340722.2500\n",
      "Epoch 331/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7096107.5000 - val_loss: 3255679.5000\n",
      "Epoch 332/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6719256.5000 - val_loss: 3200137.0000\n",
      "Epoch 333/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6827945.5000 - val_loss: 3406651.5000\n",
      "Epoch 334/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6888731.0000 - val_loss: 3288776.0000\n",
      "Epoch 335/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6946858.0000 - val_loss: 3163475.0000\n",
      "Epoch 336/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7078982.0000 - val_loss: 3098998.7500\n",
      "Epoch 337/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6742833.5000 - val_loss: 3146003.7500\n",
      "Epoch 338/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6678798.5000 - val_loss: 3284442.0000\n",
      "Epoch 339/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7028574.5000 - val_loss: 3465082.2500\n",
      "Epoch 340/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6896673.0000 - val_loss: 3313375.7500\n",
      "Epoch 341/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7027060.5000 - val_loss: 3550498.5000\n",
      "Epoch 342/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7151336.5000 - val_loss: 3234350.0000\n",
      "Epoch 343/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6765974.0000 - val_loss: 3618063.5000\n",
      "Epoch 344/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6935127.0000 - val_loss: 3195362.2500\n",
      "Epoch 345/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6991303.0000 - val_loss: 3341801.0000\n",
      "Epoch 346/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6892191.5000 - val_loss: 3252003.0000\n",
      "Epoch 347/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6874199.5000 - val_loss: 3459226.0000\n",
      "Epoch 348/500\n",
      "267/267 [==============================] - 3s 13ms/step - loss: 6981557.5000 - val_loss: 3010108.2500\n",
      "Epoch 349/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6737151.0000 - val_loss: 3209462.2500\n",
      "Epoch 350/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6926503.5000 - val_loss: 3426038.7500\n",
      "Epoch 351/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6737187.0000 - val_loss: 3130390.0000\n",
      "Epoch 352/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6685691.5000 - val_loss: 3187817.0000\n",
      "Epoch 353/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 6843349.0000 - val_loss: 3255546.2500\n",
      "Epoch 354/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7052106.5000 - val_loss: 3397577.7500\n",
      "Epoch 355/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7142830.5000 - val_loss: 3087577.5000\n",
      "Epoch 356/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6919328.5000 - val_loss: 3430729.7500\n",
      "Epoch 357/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6854603.5000 - val_loss: 3175735.0000\n",
      "Epoch 358/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 6860198.5000 - val_loss: 3099394.2500\n",
      "Epoch 359/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6786807.0000 - val_loss: 3493030.2500\n",
      "Epoch 360/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6880483.0000 - val_loss: 3098125.7500\n",
      "Epoch 361/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6747745.0000 - val_loss: 3529461.7500\n",
      "Epoch 362/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6906454.5000 - val_loss: 3577916.7500\n",
      "Epoch 363/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 6912333.0000 - val_loss: 3450877.2500\n",
      "Epoch 364/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6694956.0000 - val_loss: 3360040.7500\n",
      "Epoch 365/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 7002387.0000 - val_loss: 3287719.5000\n",
      "Epoch 366/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 7237505.0000 - val_loss: 3514719.7500\n",
      "Epoch 367/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 6985746.0000 - val_loss: 3297541.5000\n",
      "Epoch 368/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6946263.5000 - val_loss: 3383893.2500\n",
      "Epoch 369/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7041823.0000 - val_loss: 3211004.7500\n",
      "Epoch 370/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7351298.5000 - val_loss: 3377835.0000\n",
      "Epoch 371/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6971393.0000 - val_loss: 3332723.0000\n",
      "Epoch 372/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 6878276.5000 - val_loss: 3200675.0000\n",
      "Epoch 373/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 7064784.0000 - val_loss: 3111085.7500\n",
      "Epoch 374/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6758294.5000 - val_loss: 3132571.7500\n",
      "Epoch 375/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6657683.5000 - val_loss: 3126429.0000\n",
      "Epoch 376/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7035510.5000 - val_loss: 3566850.5000\n",
      "Epoch 377/500\n",
      "267/267 [==============================] - 3s 11ms/step - loss: 7457437.5000 - val_loss: 3647332.5000\n",
      "Epoch 378/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6755128.0000 - val_loss: 3346391.0000\n",
      "Epoch 379/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6934770.0000 - val_loss: 3450182.2500\n",
      "Epoch 380/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6680126.5000 - val_loss: 3110494.2500\n",
      "Epoch 381/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7100491.5000 - val_loss: 3271712.2500\n",
      "Epoch 382/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6558876.0000 - val_loss: 3159244.5000\n",
      "Epoch 383/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 6968145.5000 - val_loss: 3055280.0000\n",
      "Epoch 384/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6679101.5000 - val_loss: 3296582.0000\n",
      "Epoch 385/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6871848.0000 - val_loss: 3213569.7500\n",
      "Epoch 386/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6991623.5000 - val_loss: 3230047.0000\n",
      "Epoch 387/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6605997.5000 - val_loss: 3184731.2500\n",
      "Epoch 388/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6786552.0000 - val_loss: 3080866.7500\n",
      "Epoch 389/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6770762.5000 - val_loss: 3004071.5000\n",
      "Epoch 390/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6833106.5000 - val_loss: 3129779.2500\n",
      "Epoch 391/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 6618179.0000 - val_loss: 3232617.7500\n",
      "Epoch 392/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6953066.0000 - val_loss: 3589810.5000\n",
      "Epoch 393/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6776330.0000 - val_loss: 3843062.7500\n",
      "Epoch 394/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6672601.0000 - val_loss: 3198254.7500\n",
      "Epoch 395/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7065752.5000 - val_loss: 3670571.5000\n",
      "Epoch 396/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6937737.5000 - val_loss: 3309810.0000\n",
      "Epoch 397/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6765802.5000 - val_loss: 3411004.5000\n",
      "Epoch 398/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6832565.0000 - val_loss: 3254422.2500\n",
      "Epoch 399/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6815887.0000 - val_loss: 3135095.7500\n",
      "Epoch 400/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6744805.0000 - val_loss: 3235073.5000\n",
      "Epoch 401/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6798313.0000 - val_loss: 3537396.5000\n",
      "Epoch 402/500\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 6718390.5000 - val_loss: 3205786.2500\n",
      "Epoch 403/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6757178.5000 - val_loss: 3071474.7500\n",
      "Epoch 404/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6668592.0000 - val_loss: 3486288.0000\n",
      "Epoch 405/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6743412.0000 - val_loss: 3173760.7500\n",
      "Epoch 406/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6808204.0000 - val_loss: 3360789.2500\n",
      "Epoch 407/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6520369.5000 - val_loss: 3242143.0000\n",
      "Epoch 408/500\n",
      "267/267 [==============================] - 3s 12ms/step - loss: 7421711.5000 - val_loss: 3044961.5000\n",
      "Epoch 409/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6615647.5000 - val_loss: 3042108.0000\n",
      "Epoch 410/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6631247.0000 - val_loss: 3240714.7500\n",
      "Epoch 411/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 7099256.0000 - val_loss: 3259019.0000\n",
      "Epoch 412/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6816033.0000 - val_loss: 3387860.7500\n",
      "Epoch 413/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6710973.5000 - val_loss: 3244702.2500\n",
      "Epoch 414/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6751127.5000 - val_loss: 3107873.2500\n",
      "Epoch 415/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6692097.5000 - val_loss: 3591971.7500\n",
      "Epoch 416/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6663270.5000 - val_loss: 3087274.2500\n",
      "Epoch 417/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6810217.0000 - val_loss: 3160713.7500\n",
      "Epoch 418/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6805405.0000 - val_loss: 3663174.7500\n",
      "Epoch 419/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6459356.5000 - val_loss: 3112552.2500\n",
      "Epoch 420/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 6845834.5000 - val_loss: 3204572.5000\n",
      "Epoch 421/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6580954.0000 - val_loss: 3031742.0000\n",
      "Epoch 422/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6781101.0000 - val_loss: 2906992.2500\n",
      "Epoch 423/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6523817.5000 - val_loss: 3342091.7500\n",
      "Epoch 424/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6702841.0000 - val_loss: 3247795.2500\n",
      "Epoch 425/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7083377.5000 - val_loss: 3136467.2500\n",
      "Epoch 426/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6730587.0000 - val_loss: 3108497.0000\n",
      "Epoch 427/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6718907.5000 - val_loss: 3284796.7500\n",
      "Epoch 428/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6764780.0000 - val_loss: 3037428.5000\n",
      "Epoch 429/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6925448.5000 - val_loss: 3279064.2500\n",
      "Epoch 430/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7042617.0000 - val_loss: 3228821.5000\n",
      "Epoch 431/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6628147.5000 - val_loss: 3551213.5000\n",
      "Epoch 432/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6612585.5000 - val_loss: 3391481.5000\n",
      "Epoch 433/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6758942.5000 - val_loss: 3503948.5000\n",
      "Epoch 434/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 6643145.0000 - val_loss: 3288877.7500\n",
      "Epoch 435/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6882980.0000 - val_loss: 3115873.5000\n",
      "Epoch 436/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6709553.0000 - val_loss: 3225706.5000\n",
      "Epoch 437/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6824682.0000 - val_loss: 3044038.2500\n",
      "Epoch 438/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6896683.5000 - val_loss: 3294051.0000\n",
      "Epoch 439/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6428690.5000 - val_loss: 3454325.7500\n",
      "Epoch 440/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 6631723.5000 - val_loss: 3123947.5000\n",
      "Epoch 441/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6845454.5000 - val_loss: 3166284.0000\n",
      "Epoch 442/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6914272.0000 - val_loss: 3332385.0000\n",
      "Epoch 443/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6571795.5000 - val_loss: 3192843.5000\n",
      "Epoch 444/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6712496.5000 - val_loss: 3351363.5000\n",
      "Epoch 445/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6709084.5000 - val_loss: 3651205.5000\n",
      "Epoch 446/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 6565690.5000 - val_loss: 3322384.0000\n",
      "Epoch 447/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6399570.5000 - val_loss: 3025781.2500\n",
      "Epoch 448/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6908019.0000 - val_loss: 3299978.2500\n",
      "Epoch 449/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6992638.5000 - val_loss: 3611807.5000\n",
      "Epoch 450/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 7408981.0000 - val_loss: 3239086.2500\n",
      "Epoch 451/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6989278.5000 - val_loss: 3030782.0000\n",
      "Epoch 452/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6633385.0000 - val_loss: 3002216.2500\n",
      "Epoch 453/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6543466.0000 - val_loss: 3239086.0000\n",
      "Epoch 454/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6589576.5000 - val_loss: 3532459.0000\n",
      "Epoch 455/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6662430.5000 - val_loss: 3062260.0000\n",
      "Epoch 456/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6694767.0000 - val_loss: 3531512.5000\n",
      "Epoch 457/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6804261.5000 - val_loss: 3382765.2500\n",
      "Epoch 458/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6836907.5000 - val_loss: 3050142.5000\n",
      "Epoch 459/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 6915169.5000 - val_loss: 3388376.2500\n",
      "Epoch 460/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6559978.5000 - val_loss: 3449291.7500\n",
      "Epoch 461/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6560925.0000 - val_loss: 3295925.2500\n",
      "Epoch 462/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6708188.5000 - val_loss: 3213273.2500\n",
      "Epoch 463/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6661364.5000 - val_loss: 3183973.0000\n",
      "Epoch 464/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6997429.0000 - val_loss: 3225592.0000\n",
      "Epoch 465/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 7044098.5000 - val_loss: 3235195.2500\n",
      "Epoch 466/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6912096.0000 - val_loss: 3192482.2500\n",
      "Epoch 467/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6500164.5000 - val_loss: 3047606.5000\n",
      "Epoch 468/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6990871.5000 - val_loss: 3101946.2500\n",
      "Epoch 469/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6653712.5000 - val_loss: 3080212.2500\n",
      "Epoch 470/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 6936605.0000 - val_loss: 3337898.2500\n",
      "Epoch 471/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6528644.0000 - val_loss: 3084166.2500\n",
      "Epoch 472/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6648623.0000 - val_loss: 3098230.2500\n",
      "Epoch 473/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6697529.5000 - val_loss: 3478952.2500\n",
      "Epoch 474/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6539576.0000 - val_loss: 3411064.2500\n",
      "Epoch 475/500\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 6623936.0000 - val_loss: 3329306.2500\n",
      "Epoch 476/500\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 6917394.0000 - val_loss: 3013416.7500\n",
      "Epoch 477/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6700234.0000 - val_loss: 3264684.7500\n",
      "Epoch 478/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6644209.0000 - val_loss: 3395620.7500\n",
      "Epoch 479/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6561632.5000 - val_loss: 2978489.0000\n",
      "Epoch 480/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6679062.0000 - val_loss: 3169300.2500\n",
      "Epoch 481/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6684721.5000 - val_loss: 3088048.5000\n",
      "Epoch 482/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6611896.0000 - val_loss: 2939675.5000\n",
      "Epoch 483/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6703630.0000 - val_loss: 3206976.2500\n",
      "Epoch 484/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6571682.0000 - val_loss: 3053586.2500\n",
      "Epoch 485/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6727834.0000 - val_loss: 3227441.7500\n",
      "Epoch 486/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6715813.0000 - val_loss: 3465967.7500\n",
      "Epoch 487/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 6866464.5000 - val_loss: 3096527.2500\n",
      "Epoch 488/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6676238.5000 - val_loss: 3488466.7500\n",
      "Epoch 489/500\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 6943976.0000 - val_loss: 3299126.2500\n",
      "Epoch 490/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6870617.5000 - val_loss: 3102567.5000\n",
      "Epoch 491/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6766889.5000 - val_loss: 3265363.0000\n",
      "Epoch 492/500\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 6673987.0000 - val_loss: 3121302.5000\n",
      "Epoch 493/500\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 6495225.5000 - val_loss: 3160462.0000\n",
      "Epoch 494/500\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 6685557.5000 - val_loss: 3171649.0000\n",
      "Epoch 495/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6464048.0000 - val_loss: 3031068.2500\n",
      "Epoch 496/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6834967.5000 - val_loss: 3093579.5000\n",
      "Epoch 497/500\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 7108470.5000 - val_loss: 3107813.0000\n",
      "Epoch 498/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6262168.0000 - val_loss: 2971423.2500\n",
      "Epoch 499/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6265326.5000 - val_loss: 3083416.2500\n",
      "Epoch 500/500\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 6463673.5000 - val_loss: 2992436.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_norm, y_train, epochs=500, validation_data=(X_test_norm, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Représentation graphique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Affichage de l'évolution de la perte et de la précision\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction et evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 2992436.5000\n",
      "MSE: 2992436.5\n"
     ]
    }
   ],
   "source": [
    "# Prédiction des prix des vols\n",
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "# Évaluation du modèle\n",
    "mse = model.evaluate(X_test_norm, y_test)\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obsevation:\n",
    "J'ai remarqué qu'au fur et à mesure que j'augmente l'epoch la precision du modèle augmente en diminuant le mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prix réel</th>\n",
       "      <th>Prix prédict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>10413.0</td>\n",
       "      <td>9860.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>4030.0</td>\n",
       "      <td>4488.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>5963.0</td>\n",
       "      <td>6556.899902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>6860.0</td>\n",
       "      <td>9528.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>14571.0</td>\n",
       "      <td>13432.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>4622.0</td>\n",
       "      <td>4352.899902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>7452.0</td>\n",
       "      <td>5924.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6121.0</td>\n",
       "      <td>5206.399902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8616</th>\n",
       "      <td>13731.0</td>\n",
       "      <td>13012.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>23528.0</td>\n",
       "      <td>21341.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prix réel  Prix prédict\n",
       "4830     10413.0   9860.299805\n",
       "3771      4030.0   4488.799805\n",
       "1523      5963.0   6556.899902\n",
       "3393      6860.0   9528.400391\n",
       "4169     14571.0  13432.200195\n",
       "...          ...           ...\n",
       "9869      4622.0   4352.899902\n",
       "10061     7452.0   5924.799805\n",
       "6911      6121.0   5206.399902\n",
       "8616     13731.0  13012.599609\n",
       "8988     23528.0  21341.800781\n",
       "\n",
       "[2137 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame({\"Prix réel\": y_test, \"Prix prédict\": np.round(y_pred, 1).flatten()})\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prix réel</th>\n",
       "      <th>Prix prédict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Prix réel, Prix prédict]\n",
       "Index: []"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data['Prix réel'] == test_data['Prix prédict']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "313f9aa0f223ae78ae4f9cbf7b227f19f0baff6bff3492026b0e57b0e554386c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
